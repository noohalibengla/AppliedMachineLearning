{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Reading data"
      ],
      "metadata": {
        "id": "fgKriZsn4fCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Suppress all warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Suppress specific warnings (e.g., DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n"
      ],
      "metadata": {
        "id": "VInWKr12AyPu"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "y-Ov5tKRU7KL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv('/content/train_data.csv')\n",
        "test_data = pd.read_csv('/content/test_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.dropna(inplace=True)\n",
        "test_data.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "bsz7wbBydHNt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorizing using  Term Frequency-Inverse Document Frequency"
      ],
      "metadata": {
        "id": "lFbMxv_j4rZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Convert text to Bag of Words (BoW) representation\n",
        "vectorizer = CountVectorizer(analyzer=lambda x: x.split())\n",
        "train_bow = vectorizer.fit_transform(train_data['processed msg'])"
      ],
      "metadata": {
        "id": "4LkUZnggXwWf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "# Transform BoW into TF-IDF representation\n",
        "tfidf_converter = TfidfTransformer()\n",
        "train_tfidf = tfidf_converter.fit_transform(train_bow)\n"
      ],
      "metadata": {
        "id": "NvG_QY1xc6Mm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform validation and test sets using fitted vectorizer and transformer\n",
        "\n",
        "test_bow = vectorizer.transform(test_data['processed msg'])\n",
        "test_tfidf = tfidf_converter.transform(test_bow)\n"
      ],
      "metadata": {
        "id": "DNiJAwkcdZXe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train_data.Label.map({'ham': 0, 'spam': 1}).values\n",
        "y_test = test_data['Label'].map({'ham': 0, 'spam': 1}).values"
      ],
      "metadata": {
        "id": "gn4-bKVEj8-I"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning for best Random Forest Model"
      ],
      "metadata": {
        "id": "9Ju0vaZb46w7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the model\n",
        "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
        "\n",
        "# Define hyperparameters to tune\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Use F1-score as the metric\n",
        "f1_scorer = make_scorer(f1_score)\n",
        "\n",
        "# Perform GridSearchCV\n",
        "grid_search = GridSearchCV(rf, param_grid, scoring=f1_scorer, cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(train_tfidf, y_train)\n",
        "\n",
        "# Get the best model\n",
        "best_rf = grid_search.best_estimator_\n",
        "print(\"Best Parameters:\", grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cG2oWad9RhR",
        "outputId": "37d99b27-fc7f-4e0f-91bf-5c299bed886c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
            "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Function to print metrics\n",
        "def print_metrics(y_true, y_pred, dataset_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"{dataset_name} Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(\"-\" * 30)"
      ],
      "metadata": {
        "id": "kxZIja6hkPHo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_rf.predict(test_tfidf)\n",
        "print_metrics(y_test, y_test_pred, \"Test Set\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5K-lWHR5r0L",
        "outputId": "3b542bcb-1385-4830-8f22-43d2e6314915"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Metrics:\n",
            "Accuracy: 0.9847\n",
            "Precision: 0.9848\n",
            "Recall: 0.9847\n",
            "F1 Score: 0.9844\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetuning for best Support Vector Classifier"
      ],
      "metadata": {
        "id": "At_SqGXu5F_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Compute class weights to handle imbalance\n",
        "class_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=y_train)\n",
        "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
        "\n",
        "# Define the SVC model\n",
        "svc = SVC(kernel='linear', class_weight=class_weight_dict)\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
        "    'kernel': ['linear', 'rbf'],  # Kernel type\n",
        "    'gamma': ['scale', 'auto']  # Kernel coefficient for 'rbf'\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV with F1-score optimization\n",
        "grid_search = GridSearchCV(svc, param_grid, scoring='f1', cv=5, n_jobs=-1, verbose=1)\n",
        "grid_search.fit(train_tfidf, y_train)\n",
        "\n",
        "# Best model\n",
        "best_svc = grid_search.best_estimator_\n",
        "print(f'Best Parameters: {grid_search.best_params_}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0qTROEB9va4",
        "outputId": "db9d4369-4c15-4903-8b04-a4fd3fcab81e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "Best Parameters: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_svc.predict(test_tfidf)\n",
        "print_metrics(y_test, y_test_pred, \"Test Data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guXLsceQ19nP",
        "outputId": "553139e1-8dd4-4740-cee0-6ae12a530b70"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Data Metrics:\n",
            "Accuracy: 0.9820\n",
            "Precision: 0.9818\n",
            "Recall: 0.9820\n",
            "F1 Score: 0.9818\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine tuning for best Logistic regression"
      ],
      "metadata": {
        "id": "XHTovKYf-Enj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Define parameter grid for tuning\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 20],  # Regularization strength\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],  # Type of regularization\n",
        "    'solver' : ['saga']\n",
        "}\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "log_reg = LogisticRegression()\n",
        "\n",
        "grid_search = GridSearchCV(log_reg, param_grid, scoring='f1', cv=5, n_jobs=-1)\n",
        "grid_search.fit(train_tfidf, y_train)\n",
        "\n",
        "# Best model\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best Parameters:\", grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAbyjI9r-Jp6",
        "outputId": "8c904896-164f-47e4-d0d7-9be512a88045"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 20, 'penalty': 'l2', 'solver': 'saga'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_pred = best_model.predict(test_tfidf)\n",
        "print_metrics(y_test, y_test_pred, \"Test Data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiYCJEDFBDdi",
        "outputId": "458c7efd-0375-4a18-a2df-ec90e2ab3b96"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Data Metrics:\n",
            "Accuracy: 0.9829\n",
            "Precision: 0.9831\n",
            "Recall: 0.9829\n",
            "F1 Score: 0.9825\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Model             | Accuracy | Precision | Recall | F1 Score |\n",
        "|-------------------|----------|-----------|--------|----------|\n",
        "| **RandomForest**   | 0.9847   | 0.9848    | 0.9847 | 0.9844   |\n",
        "| **SVC**            | 0.9820   | 0.9818    | 0.9820 | 0.9818   |\n",
        "| **Logistic Regression** | 0.9829   | 0.9831    | 0.9829 | 0.9825   |\n",
        "\n",
        "### Conclusion:\n",
        "Based on the metrics, **RandomForest** outperforms both **SVC** and **Logistic Regression** in terms of accuracy, precision, recall, and F1 score, making it the best-performing model for this particular dataset. The slight differences between the models indicate that RandomForest might be more robust for this problem.\n"
      ],
      "metadata": {
        "id": "Mm50w4MdDCFr"
      }
    }
  ]
}